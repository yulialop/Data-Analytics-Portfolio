---
title: "Exploratory Data Analysis"
author: "YLG"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output:
  bookdown::html_document2:
    toc: true
    theme: cerulean
    highlight: monochrome
    number_sections: false
    fig_caption: true
    fig_width: 9.5
    code_folding: hide 
editor_options:
  chunk_output_type: inline
fontsize: 12pt 
fontfamily: Times New Roman  
geometry: "width=90%"           
---

```{r setup, message=FALSE, include=FALSE}
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  comment = NA,
  fig.pos = 'H'
)

# List of required libraries
required_libraries <- c("dplyr", "tidyverse", "ggplot2", "plotly", "RColorBrewer", "ggthemes", "kableExtra", "knitr", "broom", "scales", "rsample", "recipes", "textrecipes", "stringr", "lubridate", "syuzhet", "ggridges", "GGally", "reshape2", "xgboost", "tictoc","Metrics", "caret")


# Check and install missing libraries
for (lib in required_libraries) {
  if (!requireNamespace(lib, quietly = TRUE)) {
    install.packages(lib, dependencies = TRUE)
  }
}

library("dplyr")
library("tidyverse")
library("ggplot2")
library("plotly")
library("RColorBrewer")
library("ggthemes")
library("kableExtra")
library("knitr")
library("broom")
library("scales")
```
---


```{r}
df <- readr::read_csv("reviews_final.csv")
```
 
## Distribution of Reviews

```{r}
ggplot(df, aes(x = Rating)) +
    geom_bar(fill = "steelblue") +
    labs(
    title = "Reviews per Rating",
    x = "Rating",
    y = "Number of Reviews"
  ) +
  theme_tufte(base_family = "Times New Roman") +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.position = "top"
    )
```

```{r}
ggplot(df, aes(x = fct_rev(fct_infreq(`Main Category`)))) +
  geom_bar(fill = "steelblue") +
  labs(
    title = "Reviews per Main Category",
    x = "Main Category",
    y = "Number of Reviews"
  ) +
  coord_flip() +
  theme_tufte(base_family = "Times New Roman") +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.position = "top"
  )
```

##  Word & Sentence Counts

```{r}
ggplot(df, aes(x = `Word Count`)) +
  geom_histogram(fill = "steelblue", binwidth = 25) +
  labs(
    title = "Distribution of Review Lengths by Word Count",
    x = "Words",
    y = "Frequency"
  ) +
  theme_tufte(base_family = "Times New Roman") +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.position = "top"
  )

ggplot(df, aes(x = `Sentence Count`)) +
  geom_histogram(fill = "steelblue", binwidth = 1) +
  labs(
    title = "Distribution of Review Lengths by Sentence Count",
    x = "Sentences",
    y = "Frequency"
  ) +
  theme_tufte(base_family = "Times New Roman") +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.position = "top"
  )
```


As the below log-log plot decays sharply on a log-linear scale, a geometric distribution is more likely.
It models the number of Bernoulli trials needed for a success and produces a steep right-skew:

- High frequency of small counts (e.g., short reviews)

- Rapid drop-off as word count increases
	
A geometric distribution in word count suggests that the dataset is dominated by short, spontaneous, and unstructured text. It points to high-frequency short reviews, low content variance, and the need to consider how rare long reviews are handled — both in descriptive analysis and in transformer-based modelling.

```{r}
df |>
    count(`Word Count`) |>
    ggplot(aes(x = `Word Count`, y = n)) +
    geom_point(color = "steelblue") +
    scale_x_log10() +
    scale_y_log10() +
    labs(title = "Log-Log Plot of Word Counts", x = "Log Word Count", y = "Log Frequency") +
  theme_tufte(base_family = "Times New Roman") +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.position = "top"
  )
```


```{r}

df_boxplot <- df |>
  select(Rating, `Word Count`, `Sentence Count`) |>
  pivot_longer(
    cols = c(`Word Count`, `Sentence Count`),
    names_to = "metric",
    values_to = "value"
  )


ggplot(df_boxplot, aes(x = factor(Rating), y = value)) +
  geom_boxplot(fill = "steelblue") +
    facet_wrap(~metric, scales = "free_y") +
  labs(
    title = "Distribution of Review Lengths by Rating",
    x = "Rating",
    y = "Word Count"
  ) +
  theme_tufte(base_family = "Times New Roman") +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.position = "top"
  )
```


```{r}
# Generate summary statistics for the actual target variable
glance(summary(df$`Word Count`)) |> 
    kable(
      caption = "Summary Statistics of the Word Count for Full Reviews", 
      digits = 2
    ) |> 
      kable_styling(
      position = "center",
    full_width = FALSE                            
  ) 
```

```{r}
# # Generate summary statistics for the actual target variable
glance(summary(df$`Sentence Count`)) |>
    kable(
      caption = "Summary Statistics of the Sentence Count for Full Reviews",
      digits = 2
    ) |>
      kable_styling(
      position = "center",
    full_width = FALSE
  )
```


``` {r}
get_modes <- function(v) {
  uniqv <- unique(v)
  freq <- tabulate(match(v, uniqv))
  uniqv[freq == max(freq)]
}

get_modes(df$`Sentence Count`)

```

## Word Cloud

```{r}
library(tidytext)
library(dplyr)
library(stringr)
library(wordcloud)

custom_stopwords <- bind_rows(
  stop_words,
  tibble(word = c("it's", "i'm", "they're", "we're", "you'll"), lexicon = "custom")
)

word_counts <- df |>
  unnest_tokens(word, Review) |>
  filter(!word %in% custom_stopwords$word) |>
  count(word, sort = TRUE)

word_counts |>
  with(wordcloud(word, n, max.words = 100, colours = brewer.pal(8, "Blues")))
```

```{r}
# Create a dummy dataframe for the legend
legend_df <- data.frame(
  rating_group = factor(1:5),
  x = 1:5,
  y = 1
)

# Define colours for each rating level
rating_colours <- c(
  "1" = "#d73027",  # red
  "2" = "#fc8d59",  # orange
  "3" = "#F1CE63",  # yellow
  "4" = "#8CD17D",  # light green
  "5" = "#59A14F"   # dark green
)

# Create a custom legend
ggplot(legend_df, aes(x, y, fill = rating_group)) +
  geom_tile() +
  scale_fill_manual(values = rating_colours, name = "Mean Rating") +
  theme_void() +
  theme(legend.position = "top")
```

##  TF-IDF & N-grams


```{r}
library(tidytext)
library(textclean)
library(stringr)

# Tokenise by word and clean
word_tokens <- df |>
  mutate(Review = replace_contraction(Review)) |>
  unnest_tokens(word, Review) |>
  anti_join(custom_stopwords, by = "word") |>
  filter(!str_detect(word, "^\\d+$"))  # remove pure numbers

# Most common words per rating
word_freq <- word_tokens |>
  count(Rating, word, sort = TRUE)

# Distinctive words using TF-IDF
word_tf_idf <- word_freq |>
  bind_tf_idf(term = word, document = Rating, n = n) |>
  group_by(Rating) |>
  slice_max(tf_idf, n = 10, with_ties = FALSE) |>
  ungroup()

# Plot TF-IDF words
ggplot(word_tf_idf, aes(x = reorder_within(word, tf_idf, Rating), y = tf_idf, fill = as.factor(Rating))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~Rating, scales = "free") +
  scale_x_reordered() +
  scale_fill_manual(values = rating_colours) +
  labs(title = "Top Distinctive Words by Rating",
       x = "", y = "TF-IDF") +
  coord_flip() +
  theme_tufte(base_family = "Times New Roman") +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.position = "none"
  )
```

``` {r}
# WORD analysis
words <- df |>
  mutate(Review = replace_contraction(Review)) |>
  unnest_tokens(word, Review, token = "words") |>
  filter(!word %in% custom_stopwords$word,
         !str_detect(word, "^\\d+$"))

# Count top words per rating
top_words <- words |>
  count(Rating, word, sort = TRUE) |>
  group_by(Rating) |>
  slice_max(n, n = 10, with_ties = FALSE) |>
  ungroup()

# Plot words
ggplot(top_words, aes(x = reorder_within(word, n, Rating), y = n, fill = as.factor(Rating))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~Rating, scales = "free") +
  scale_x_reordered() +
  scale_fill_manual(values = rating_colours) +
  labs(title = "Most Frequent Words by Rating",
       x = "Word", y = "Count") +
  coord_flip() +
  theme_tufte(base_family = "Times New Roman") +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.position = "none"
  )
```

```{r}
# BIGRAM analysis
bigrams <- df |>
  mutate(Review = replace_contraction(Review)) |>
  unnest_tokens(bigram, Review, token = "ngrams", n = 2)

# Separate and remove stop words from bigrams
bigrams_separated <- bigrams |>
  separate(bigram, into = c("word1", "word2"), sep = " ") |>
  filter(!word1 %in% custom_stopwords$word,
         !word2 %in% custom_stopwords$word,
         !str_detect(word1, "^\\d+$"),
         !str_detect(word2, "^\\d+$")) |>
  unite(bigram, word1, word2, sep = " ")

# Count top bigrams per rating
top_bigrams <- bigrams_separated |>
  count(Rating, bigram, sort = TRUE) |>
  group_by(Rating) |>
  slice_max(n, n = 10, with_ties = FALSE) |>
  ungroup()

# Plot bigrams
ggplot(top_bigrams, aes(x = reorder_within(bigram, n, Rating), y = n, fill = as.factor(Rating))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~Rating, scales = "free") +
  scale_x_reordered() +
  scale_fill_manual(values = rating_colours) +
  labs(title = "Most Frequent Bigrams by Rating",
       x = "Bigram", y = "Count") +
  coord_flip() +
  theme_tufte(base_family = "Times New Roman") +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.position = "none"
  )
```

```{r}
# TRIGRAM analysis
trigrams <- df |>
  mutate(Review = replace_contraction(Review)) |>
  unnest_tokens(trigram, Review, token = "ngrams", n = 3)

# Separate and remove stop words from trigrams
trigrams_separated <- trigrams |>
  separate(trigram, into = c("word1", "word2", "word3"), sep = " ") |>
  filter(
    !word1 %in% custom_stopwords$word,
    !word2 %in% custom_stopwords$word,
    !word3 %in% custom_stopwords$word,
    !str_detect(word1, "^\\d+$"),
    !str_detect(word2, "^\\d+$"),
    !str_detect(word3, "^\\d+$")
  ) |>
  unite(trigram, word1, word2, word3, sep = " ")

# Count top trigrams per rating
top_trigrams <- trigrams_separated |>
  count(Rating, trigram, sort = TRUE) |>
  group_by(Rating) |>
  slice_max(n, n = 10, with_ties = FALSE) |>
  ungroup()

# Plot trigrams
ggplot(top_trigrams, aes(x = reorder_within(trigram, n, Rating), y = n, fill = as.factor(Rating))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~Rating, scales = "free") +
  scale_x_reordered() +
  scale_fill_manual(values = rating_colours) +
  labs(title = "Most Frequent Trigrams by Rating",
       x = "Trigram", y = "Count") +
  coord_flip() +
  theme_tufte(base_family = "Times New Roman") +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.position = "none"
  )
```

## Sentiment vs. Rating

When comparing text-based sentiment scores to the actual star ratings, this can reveal:

- Misalignments (e.g., 5-star ratings with negative sentiment)

- Review quality or credibility issues
	
Explore misalignments, for example: filter for 1-star or 2-star reviews with high positive sentiment, or 5-star reviews with negative sentiment. 

The mismatches could be due to failure of the model to consider context, especially if reviews were editted later.
	
To visualise sentiment–rating mismatches, a good approach is to plot sentiment scores against star ratings and highlight misaligned reviews. 

```{r}

df_emotions <- readr::read_csv("reviews_final.csv")

# Example thresholds for misalignment
threshold_positive <- 4   # unusually high sentiment for low rating
threshold_negative <- 3  # unusually low sentiment for high rating

misaligned_reviews <- df_emotions |>
  filter(
    (Rating <= 2 & `Sentiment Score` > threshold_positive) |
    (Rating >= 4 & `Sentiment Score` < threshold_negative)
  )


# Add mismatch classification
reviews_df <- df_emotions |>
  mutate(misaligned = case_when(
    Rating <= 2 & `Sentiment Score` >= threshold_positive ~ "High Sentiment, Low Rating",
    Rating >= 4 & `Sentiment Score` < threshold_negative ~ "Low Sentiment, High Rating",
    Rating == 3 & (`Sentiment Score` > 4 | `Sentiment Score` < 2) ~ "Neutral Rating, Strong Sentiment",
    TRUE ~ "Aligned"
  ))

# Visualise
ggplot(reviews_df, aes(x = factor(Rating), y = `Sentiment Score`, colour = misaligned)) +
  geom_jitter(width = 0.2, alpha = 0.6) +
  scale_colour_manual(values = c("High Sentiment, Low Rating" = "green3", 
                                 "Low Sentiment, High Rating" ="red", 
                                 "Neutral Rating, Strong Sentiment" = "orange",
                                 "Aligned" = "grey60")) +
  labs(x = "Rating", y = "Sentiment Score", 
       title = "Sentiment vs Rating: Highlighting Misaligned Reviews",
       colour = "Mismatch Status") +
  theme_tufte(base_family = "Times New Roman") +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.position = "top"
  )
```


```{r}
library(dplyr)
library(psych)

df |> 
  select(where(is.numeric), -`Word Count`) |> 
  psych::describe()
```



```{r}
Hmisc::describe(df)
```

```{r}
df_sampled <- readr::read_csv("reviews_clean.csv")

# Summary of detected anomalies in the dataset
anomalies <- xray::anomalies(df_sampled)

knitr::kable(
  anomalies$variables, 
  caption = "Summary of Detected Anomalies in the Stratified Sample")
```

